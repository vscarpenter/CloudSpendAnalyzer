# Default configuration for AWS Cost Explorer CLI

# LLM Provider Configuration
llm_provider: "openai"  # openai, anthropic, bedrock, ollama
llm_config:
  openai:
    model: "gpt-3.5-turbo"
    temperature: 0.1
    max_tokens: 1000
  anthropic:
    model: "claude-3-haiku-20240307"
    temperature: 0.1
    max_tokens: 1000
  bedrock:
    model: "anthropic.claude-3-haiku-20240307-v1:0"
    region: "us-east-1"
  ollama:
    model: "llama2"
    base_url: "http://localhost:11434"

# AWS Configuration
default_profile: null  # Use default AWS profile if not specified
aws_region: "us-east-1"

# Cache Configuration
cache_ttl: 3600  # Cache TTL in seconds (1 hour)
cache_directory: "~/.aws-cost-cli/cache"

# Output Configuration
output_format: "simple"  # simple, detailed, json
default_currency: "USD"
date_format: "%Y-%m-%d"

# Query Configuration
default_granularity: "MONTHLY"
max_results: 100